{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Simulate CLI Auth from MLops"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import repackage\r\n",
    "repackage.add(\"../../azure-enterprise-scale-ml/esml/common/\")\r\n",
    "import azureml.core\r\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\r\n",
    "from esml import ESMLProject\r\n",
    "print(\"SDK Version:\", azureml.core.VERSION)\r\n",
    "\r\n",
    "def init_ws():\r\n",
    "    p = ESMLProject() # self-aware about its config sources\r\n",
    "\r\n",
    "    # WRITE ws config - simulate CLI auth with Interactive\r\n",
    "    cli_auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\r\n",
    "    ws, config_name = p.authenticate_workspace_and_write_config(cli_auth)\r\n",
    "    # TEST read\r\n",
    "    ws = p.get_workspace_from_config(cli_auth) # Authenticate to DEV\r\n",
    "    p.ws = ws\r\n",
    "    return p\r\n",
    "    \r\n",
    "p = init_ws()\r\n",
    "p.describe()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SDK Version: 1.26.0\n",
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning: Falling back to use azure cli login credentials.\n",
      "If you run your code in unattended mode, i.e., where you can't give a user input, then we recommend to use ServicePrincipalAuthentication or MsiAuthentication.\n",
      "Please refer to aka.ms/aml-notebook-auth for different authentication mechanisms in azureml-sdk.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Inference version: 1\n",
      "\n",
      " - ds01_diabetes\n",
      "projects/project002/11_diabetes_model_reg/inference/1/ds01_diabetes/in/dev/2021/06/08/\n",
      "projects/project002/11_diabetes_model_reg/inference/1/ds01_diabetes/out/bronze/dev/\n",
      "projects/project002/11_diabetes_model_reg/inference/1/ds01_diabetes/out/silver/dev/\n",
      "\n",
      " - ds02_other\n",
      "projects/project002/11_diabetes_model_reg/inference/1/ds02_other/in/dev/2021/06/08/\n",
      "projects/project002/11_diabetes_model_reg/inference/1/ds02_other/out/bronze/dev/\n",
      "projects/project002/11_diabetes_model_reg/inference/1/ds02_other/out/silver/dev/\n",
      " \n",
      "\n",
      "Training GOLD (p.GoldPath)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/\n",
      " \n",
      "\n",
      "[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\n",
      "A)INFERENCE ONLINE: GOLD to score (example if realtime - today)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/2021_10_20/495bda3ecbe949e2aaf66dd0ca666505/\n",
      " \n",
      "\n",
      "A)INFERENCE ONLINE: GOLD scored (example if realtime today)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/scored/dev/2021_10_20/495bda3ecbe949e2aaf66dd0ca666505/\n",
      " \n",
      "\n",
      "[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\n",
      "B)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/2021_06_08/8ee9fea0baad416396a35d361c34e3e9/\n",
      " \n",
      "\n",
      "B)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/scored/dev/2021_06_08/8ee9fea0baad416396a35d361c34e3e9/\n",
      " \n",
      "\n",
      "C) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\n",
      "projects/project002/11_diabetes_model_reg/inference/1/gold/dev/2021_06_08/8ee9fea0baad416396a35d361c34e3e9/2021_06_08/\n",
      "projects/project002/11_diabetes_model_reg/inference/1/scored/dev/2021_06_08/8ee9fea0baad416396a35d361c34e3e9/2021_06_08/\n",
      " \n",
      "\n",
      "ENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\n",
      "ACTIVE ENVIRONMENT = dev\n",
      "ACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n",
      "- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n",
      "- msft-weu-DEV-eap-proj02_ai-amls\n",
      "- westeurope\n",
      "- MSFT-WEU-EAP_CMN_AI-DEV-RG\n",
      "Active vNet: msft-weu-dev-cmnai-vnet\n",
      "Active SubNet: \n",
      "[USAGE] for the above: p.vNetForActiveEnvironment()\n",
      "Active Lake (storage account)  msftweudevcmnai2\n",
      "[USAGE] for the above: p.getLakeForActiveEnvironment()\n",
      "AML for docker: True\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 10"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\"\"\"\r\n",
    "Copyright (C) Microsoft Corporation. All rights reserved.​\r\n",
    " ​\r\n",
    "Microsoft Corporation (“Microsoft”) grants you a nonexclusive, perpetual,\r\n",
    "royalty-free right to use, copy, and modify the software code provided by us\r\n",
    "(\"Software Code\"). You may not sublicense the Software Code or any use of it\r\n",
    "(except to your affiliates and to vendors to perform work on your behalf)\r\n",
    "through distribution, network access, service agreement, lease, rental, or\r\n",
    "otherwise. This license does not purport to express any claim of ownership over\r\n",
    "data you may have shared with Microsoft in the creation of the Software Code.\r\n",
    "Unless applicable law gives you more rights, Microsoft reserves all other\r\n",
    "rights not expressly granted herein, whether by implication, estoppel or\r\n",
    "otherwise. ​\r\n",
    " ​\r\n",
    "THE SOFTWARE CODE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS\r\n",
    "OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\r\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\r\n",
    "MICROSOFT OR ITS LICENSORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\r\n",
    "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\r\n",
    "PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR\r\n",
    "BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER\r\n",
    "IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\r\n",
    "ARISING IN ANY WAY OUT OF THE USE OF THE SOFTWARE CODE, EVEN IF ADVISED OF THE\r\n",
    "POSSIBILITY OF SUCH DAMAGE.\r\n",
    "\"\"\"\r\n",
    "#import repackage\r\n",
    "#repackage.add(\"../../azure-enterprise-scale-ml/esml/common/\")\r\n",
    "#import azureml.core\r\n",
    "#from azureml.core.authentication import AzureCliAuthentication\r\n",
    "#from esml import ESMLProject\r\n",
    "#print(\"SDK Version:\", azureml.core.VERSION)\r\n",
    "\r\n",
    "#p = ESMLProject.get_project_from_env_command_line() # Alt A)\r\n",
    "#print(\"ESML environment (dev, test or prod): {}\".format(p.dev_test_prod))\r\n",
    "#p.describe()\r\n",
    "#cli_auth = AzureCliAuthentication()\r\n",
    "#ws, config_name = p.authenticate_workspace_and_write_config(cli_auth) \r\n",
    "\r\n",
    "p = init_ws() # Simulates the \"commented code above\"-to authentica and create ESMLProject\r\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\r\n",
    "ws = p.ws\r\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "msft-weu-DEV-eap-proj02_ai-amls\n",
      "MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n",
      "westeurope\n",
      "ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 21 Bronze 2 Gold"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "p = init_ws()\r\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\r\n",
    "p.init(p.ws) # Automapping from datalake to Azure ML datasets, prints status\r\n",
    "\r\n",
    "\r\n",
    "import repackage\r\n",
    "repackage.add(\"../../azure-enterprise-scale-ml/esml/common/\")\r\n",
    "from esml import ESMLProject\r\n",
    "from baselayer_azure_ml_pipeline import ESMLPipelineFactory, esml_pipeline_types\r\n",
    "\r\n",
    "#p = ESMLProject()\r\n",
    "p.inference_mode = False\r\n",
    "p.active_model = 12 # Y=11, price=12\r\n",
    "p_factory = ESMLPipelineFactory(p)\r\n",
    "\r\n",
    "scoring_date = '2021-01-01 10:35:01.243860'\r\n",
    "p_factory.batch_pipeline_parameters[1].default_value = scoring_date # overrides ESMLProject.date_scoring_folder.\r\n",
    "\r\n",
    "p_factory.describe()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  2021/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "\n",
      "Inference mode (False = Training mode): False\n",
      "Load data as Datasets....\n",
      "ds01_diabetes\n",
      "ds02_other\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n",
      "\n",
      " ---- Q: WHICH files are generated as templates, for you to EDIT? ---- \n",
      "A: These files & locations:\n",
      "File to EDIT (step: IN_2_SILVER_1): ../../../2_A_aml_pipeline/4_inference/batch/M12/in2silver_ds01_vw.py\n",
      "File to EDIT (step: IN_2_SILVER_2): ../../../2_A_aml_pipeline/4_inference/batch/M12/in2silver_ds02_audi.py\n",
      "File to EDIT (step: IN_2_SILVER_3): ../../../2_A_aml_pipeline/4_inference/batch/M12/in2silver_ds03_bmw.py\n",
      "File to EDIT (step: SILVER_MERGED_2_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M12/silver_merged_2_gold.py\n",
      "File to EDIT (step: SCORING_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M12/scoring_gold.py\n",
      "File to EDIT a lot (reference in step-scripts Custom code): ../../../2_A_aml_pipeline/4_inference/batch/M12/your_code/your_custom_code.py\n",
      "\n",
      " ---- WHAT model to SCORE with, & WHAT data 'date_folder'? ---- \n",
      "InferenceModelVersion (model version to score with): 1\n",
      "Date_scoring_folder (data to score) : 2021-01-01 10:35:01.243860\n",
      "ESML environment: dev\n",
      "\n",
      " ---- ESML Datalake locations: ESML Datasets (IN-data) ---- \n",
      "Name (lake folder): ds01_vw and AzureName IN: M12_ds01_vw_train_IN\n",
      "IN projects/project002/12_car_price_regression/train/ds01_vw/in/dev/2021/01/01/\n",
      "Bronze projects/project002/12_car_price_regression/train/ds01_vw/out/bronze/dev/\n",
      "Silver projects/project002/12_car_price_regression/train/ds01_vw/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds02_audi and AzureName IN: M12_ds02_audi_train_IN\n",
      "IN projects/project002/12_car_price_regression/train/ds02_audi/in/dev/2021/01/01/\n",
      "Bronze projects/project002/12_car_price_regression/train/ds02_audi/out/bronze/dev/\n",
      "Silver projects/project002/12_car_price_regression/train/ds02_audi/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds03_bmw and AzureName IN: M12_ds03_bmw_train_IN\n",
      "IN projects/project002/12_car_price_regression/train/ds03_bmw/in/dev/2021/01/01/\n",
      "Bronze projects/project002/12_car_price_regression/train/ds03_bmw/out/bronze/dev/\n",
      "Silver projects/project002/12_car_price_regression/train/ds03_bmw/out/silver/dev/\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `IN_2_GOLD` or `IN_2_GOLD_TRAIN`\r\n",
    "- This since `p.inference_mode=False`\r\n",
    "    - Otherwise if we want a SCORNING Pipeline, we flip this flag `p.inference_mode=TRUE`, and create `IN_2_GOLD_SCORING`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print(p.inference_mode)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "False\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "## CREATE - IN_2_GOLD\r\n",
    "p_factory.create_dataset_scripts_from_template(overwrite_if_exists=False) \r\n",
    "batch_pipeline = p_factory.create_batch_pipeline(esml_pipeline_types.IN_2_GOLD) # Prepare data for training: Either with AutoMLStep or ManualMLStep\r\n",
    "\r\n",
    "## RUN pipeline\r\n",
    "pipeline_run = p_factory.execute_pipeline(batch_pipeline)\r\n",
    "pipeline_run.wait_for_completion(show_output=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Did NOT overwrite script-files with template-files such as 'scoring_gold.py', since overwrite_if_exists=False\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = FALSE. [active_in_folder.json,active_scoring_in_folder.json] not found in LAKE. \n",
      " - Using [active_in_folder.json,active_scoring_in_folder.json] from ArgParse or GIT. No override from datalake settings\n",
      "Path for active folder (where no files exists):\n",
      "AdlsGen2-ListFiles (req=1, existingItems=0)' for 'https://msftweudevcmnai2.dfs.core.windows.net/lake3?directory=projects/project002/12_car_price_regression/train/active&recursive=true&resource=filesystem' on storage failed with status code 'NotFound' (The specified path does not exist.), client request ID '546c816e-a842-4072-bbaf-30e145da135f', request ID '22cc8ab0-f01f-0023-2e54-c5fa13000000\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster prj02-m12-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = prj02-m12-dev\n",
      "Created step IN 2 SILVER - ds01_vw [10297ca4][467d75d9-139b-4991-a4e9-ce68ac498ddd], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds02_audi [4309b5e6][c1f03097-e6ed-4b06-976a-f9ae9bc1f46b], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds03_bmw [05ecfab5][791ad5c9-6f4a-41c1-ba54-a6b0e23f7b6a], (This step will run and generate new outputs)\n",
      "Created step SILVER MERGED 2 GOLD [08fa668c][4cc7db1d-7e70-40d0-b19c-9eca18e4d3a6], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun f00eb35b-e10f-417f-a635-158256e15655\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f00eb35b-e10f-417f-a635-158256e15655?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution!\n",
      "PipelineRunId: f00eb35b-e10f-417f-a635-158256e15655\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f00eb35b-e10f-417f-a635-158256e15655?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "{'runId': 'f00eb35b-e10f-417f-a635-158256e15655', 'status': 'Completed', 'startTimeUtc': '2021-10-20T01:45:21.439659Z', 'endTimeUtc': '2021-10-20T01:55:38.453627Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{\"esml_inference_model_version\":\"1\",\"esml_scoring_folder_date\":\"2021-01-01 10:35:01.243860\",\"esml_optional_unique_scoring_folder\":\"*\",\"esml_environment_dev_test_prod\":\"dev\",\"esml_inference_mode\":\"0\"}', 'azureml.pipelineComponent': 'pipelinerun'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://sajxvzyuylcu5jc.blob.core.windows.net/azureml/ExperimentRun/dcid.f00eb35b-e10f-417f-a635-158256e15655/logs/azureml/executionlogs.txt?sv=2019-07-07&sr=b&sig=E%2BQFdryMaS%2BX6P9XvGxCT17HOwFTQEvRcFluOqkKWM8%3D&skoid=bd6cbaae-1027-4ac2-b1e7-dea7bd468eb3&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-19T22%3A18%3A31Z&ske=2021-10-21T06%3A28%3A31Z&sks=b&skv=2019-07-07&st=2021-10-20T01%3A41%3A13Z&se=2021-10-20T09%3A51%3A13Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://sajxvzyuylcu5jc.blob.core.windows.net/azureml/ExperimentRun/dcid.f00eb35b-e10f-417f-a635-158256e15655/logs/azureml/stderrlogs.txt?sv=2019-07-07&sr=b&sig=7T2DYVCXsW%2By%2BgPtWd74AgMEIkzrrwNisClugSDhw7w%3D&skoid=bd6cbaae-1027-4ac2-b1e7-dea7bd468eb3&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-19T22%3A18%3A31Z&ske=2021-10-21T06%3A28%3A31Z&sks=b&skv=2019-07-07&st=2021-10-20T01%3A41%3A13Z&se=2021-10-20T09%3A51%3A13Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://sajxvzyuylcu5jc.blob.core.windows.net/azureml/ExperimentRun/dcid.f00eb35b-e10f-417f-a635-158256e15655/logs/azureml/stdoutlogs.txt?sv=2019-07-07&sr=b&sig=DzPQlZyFZN46wmxtHSe1z%2FG1sL96FNVUFJOhfp3NcHM%3D&skoid=bd6cbaae-1027-4ac2-b1e7-dea7bd468eb3&sktid=72f988bf-86f1-41af-91ab-2d7cd011db47&skt=2021-10-19T22%3A18%3A31Z&ske=2021-10-21T06%3A28%3A31Z&sks=b&skv=2019-07-07&st=2021-10-20T01%3A41%3A13Z&se=2021-10-20T09%3A51%3A13Z&sp=r'}, 'submittedBy': 'Joakim Åström'}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 22 - TRAIN step"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from azureml.train.automl import AutoMLConfig\r\n",
    "from esml import ESMLDataset, ESMLProject\r\n",
    "from baselayer_azure_ml import AutoMLFactory,azure_metric_regression,azure_metric_classification\r\n",
    "\r\n",
    "p = init_ws()\r\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\r\n",
    "p.init(ws) # Automapping from datalake to Azure ML datasets, prints status\r\n",
    "\r\n",
    "# TRAIN MODEL\r\n",
    "automl_performance_config = p.get_automl_performance_config() # 1)Get config\r\n",
    "aml_compute = p.get_training_aml_compute(ws) # 2)Get compute, for active environment\r\n",
    "\r\n",
    "label = p.active_model[\"label\"]\r\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6) # 3) Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST)          # Alt: p.Gold.random_split(percentage=0.8, seed=23)\r\n",
    "\r\n",
    "automl_config = AutoMLConfig(task = 'regression', # 4) Override the ENV config, for model(that inhertits from enterprise DEV_TEST_PROD config baseline)\r\n",
    "                            primary_metric = azure_metric_regression.MAE, # # Note: Regression(MAPE) are not possible in AutoML\r\n",
    "                            compute_target = aml_compute,\r\n",
    "                            training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\r\n",
    "                            experiment_exit_score = '0.9', # DEMO purpose\r\n",
    "                            label_column_name = label,\r\n",
    "                            **automl_performance_config\r\n",
    "                        )\r\n",
    "via_pipeline = False\r\n",
    "# Consistent/same return values from both AutoML ALTERNATIVES (run or pipeline)\r\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "print(esml_pipeline_types.IN_2_GOLD)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "IN_2_GOLD\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 23 - compare scoring\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\r\n",
    "p = init_ws()\r\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\r\n",
    "\r\n",
    "# COMPARE MODEL SCORING - Promote?\r\n",
    "target_env = \"dev\" # If not set or used, it will automatically test for NEXT environment\r\n",
    "print(\"Example: If new model scores better in DEV, we can promote this to TEST\")\r\n",
    "\r\n",
    "promote, m1_name, r1_id, m2_name, r2_run_id = AutoMLFactory(p).compare_scoring_current_vs_new_model(target_env)\r\n",
    "\r\n",
    "print(\"New Model: {} in environment {}\".format(m1_name, p.dev_test_prod))\r\n",
    "print(\"Existing Model: {} in environment {}\".format(m2_name,target_env))\r\n",
    "\r\n",
    "if (promote and p.dev_test_prod == target_env):# Can only register a model in same workspace (test->test) - need to retrain if going from dev->test\r\n",
    "    AutoMLFactory(p).register_active_model(target_env)\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example: If new model scores better in DEV, we can promote this to TEST\n",
      "Loading AutoML config settings from: dev\n",
      "targe=source environement. Compare model version in DEV/TEST/PROD with latest registered in same DEV/TEST/PROD workspace (same workspace & subscriptiom comparison)\n",
      "\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.30.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "TARGET is in the same Azure ML Studio workspace as SOURCE, comparing with latest registered model...\n",
      "target_best_run_id AutoML_1cc989cd-81d3-4693-b5a9-b2ae9188302f\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.30.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "New trained model & cached RUN, has TASK_TYPE: regression and Best_Run_id: AutoML_1cc989cd-81d3-4693-b5a9-b2ae9188302f_0\n",
      "Target model & RUN, in Azure ML Studio workspace to compare with, has TASK_TYPE: regression and Best_Run_id: \n",
      "\n",
      "Q: Do we have SCORING DRIFT / CONCEPT DRIFT?\n",
      "Q: Is a model trained on NEW data better? Is the one in production degraded? (not fit for the data it scores - real world changed, other CONCEPT)\n",
      "A: - Lets check. Instead of DataDrift, lets look at actual SCORING on new data (or same data, other code). See if we should PROMOTE newly trained model...\n",
      "\n",
      "New trained model: \n",
      "RMSE (normalized_root_mean_squared_error): 0.25367474015281405\n",
      "MAPE (Mean average Percentage Error): 47.73639492683337\n",
      "MAE (normalized_mean_absolute_error): 0.21601394568522597\n",
      "R2 (r2_score): -0.010634855762826967\n",
      "Spearman (spearman_correlation): -1.0\n",
      "\n",
      "Target model, to compare with; \n",
      "RMSE (normalized_root_mean_squared_error): 0.25367474015281405\n",
      "MAPE (Mean average Percentage Error): 47.73639492683337\n",
      "MAE (normalized_mean_absolute_error): 0.21601394568522597\n",
      "R2 (r2_score): -0.010634855762826967\n",
      "Spearman (spearman_correlation): -1.0\n",
      "\n",
      "Selected metrics, and weights, to be used when comparing for promotion/scoring drift\n",
      "Metric weight: RMSE_promote_weight is 0.0200\n",
      "Metric VALUE (incl. weight) 0.2337 (without weight:  0.2537)\n",
      "\n",
      "Metric weight: R2_promote_weight is -0.0010\n",
      "Metric VALUE (incl. weight) -0.0096 (without weight:  -0.0106)\n",
      "\n",
      "Metric weight: Spearman_promote_weight is -0.0010\n",
      "Metric VALUE (incl. weight) -0.9990 (without weight:  -1.0000)\n",
      "\n",
      "\n",
      "Promote model = True\n",
      "New Model: AutoML1cc989cd80 in environment dev\n",
      "Existing Model: AutoML1cc989cd80 in environment dev\n",
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "model.version 6\n",
      "Model name AutoML1cc989cd80 is registered.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 31 - deploy to DEV"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "p = init_ws()\n",
    "#p.init(ws) # Automapping from datalake to Azure ML datasets, prints status\n",
    "\n",
    "print(\"Environment:\")\n",
    "print(p.dev_test_prod,p.ws.name)\n",
    "\n",
    "# DEPLOY!\n",
    "inference_config, model, best_run = p.get_active_model_inference_config(p.ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Environment:\n",
      "dev msft-weu-DEV-eap-proj02_ai-amls\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.30.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "Deploying model: AutoML1cc989cd80 with verison: 6 to environment: dev with overwrite_endpoint=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "image_build_compute = prj02-m03-dev\n",
      "Found existing AksWebservice endpoint, deleting it, since overwrite=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster, esml-dev-prj02, using it.\n",
      "Note: Autoscale_enabled=False, or since aks_dev_test=True in config, autoscaling is automatically shut off, e.g. overridden in config (since not supported) for environment dev\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-22 01:28:43+02:00 Creating Container Registry if not exists.\n",
      "2021-06-22 01:28:43+02:00 Registering the environment.\n",
      "2021-06-22 01:28:44+02:00 Use the existing image.\n",
      "2021-06-22 01:28:46+02:00 Creating resources in AKS.\n",
      "2021-06-22 01:28:46+02:00 Submitting deployment to compute.\n",
      "2021-06-22 01:28:48+02:00 Checking the status of deployment esml-dev-p02-m03-aksapi..\n",
      "2021-06-22 01:29:10+02:00 Checking the status of inference endpoint esml-dev-p02-m03-aksapi.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2021-06-21T23:28:55,706924207+00:00 - iot-server/run \n",
      "2021-06-21T23:28:55,710092567+00:00 - rsyslog/run \n",
      "2021-06-21T23:28:55,713865619+00:00 - gunicorn/run \n",
      "rsyslogd: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "2021-06-21T23:28:55,728396335+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-21T23:28:55,812743163+00:00 - iot-server/finish 1 0\n",
      "2021-06-21T23:28:55,814000747+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 40\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Initializing logger\n",
      "2021-06-21 23:28:57,023 | root | INFO | Starting up app insights client\n",
      "2021-06-21 23:28:57,024 | root | INFO | Starting up request id generator\n",
      "2021-06-21 23:28:57,024 | root | INFO | Starting up app insight hooks\n",
      "2021-06-21 23:28:57,024 | root | INFO | Invoking user's init function\n",
      "2021-06-21 23:28:59,228 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "2021-06-21 23:28:59,473 | root | INFO | Users's init has completed successfully\n",
      "2021-06-21 23:28:59,475 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-06-21 23:28:59,475 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-06-21 23:28:59,476 | root | INFO | Scoring timeout is found from os.environ: 300000 ms\n",
      "2021-06-21 23:29:10,534 | root | INFO | 200\n",
      "127.0.0.1 - - [21/Jun/2021:23:29:10 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "2021-06-21 23:29:21,906 | root | INFO | 200\n",
      "127.0.0.1 - - [21/Jun/2021:23:29:21 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "\n",
      "Deployed AKS Webservice: esml-dev-p02-m03-aksapi \n",
      "Webservice Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/score \n",
      "Webservice API_Secret are stored in keyvault with name: esml-dev-p02-m03-apisecret \n",
      "Webservice API_URI are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice Swagger Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/swagger.json\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 31 - TEST DEV webservice"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "p = init_ws()\n",
    "p.inference_mode = True \n",
    "p.connect_to_lake() # To be able to also SAVE scoring autmatically\n",
    "\n",
    "# Get TEST-data\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Get  X_test data, ESML knowsSPLIT and LABEL already \n",
    "print(tags)\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test,False) # Auto-fetch key from keyvault, and calls the webservice\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GEN2 as Datastore\n",
      "M03_GOLD_VALIDATE : (37, 11)\n",
      "X_test  (37, 10)\n",
      "y_test  (37,)\n",
      "{'split_percentage': '0.2', 'label': 'Y', 'model': '03_diabetes_model_reg'}\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Note: Fetching keys automatically via workspace keyvault.\n",
      "Saving scoring to lake for project folder project002 and inference_model_version: 6 ...\n",
      "...\n",
      "..\n",
      "\n",
      "Saved DATA to score successfully in LAKE, as file 'to_score_False.parquet'\n",
      "..\n",
      "Saved SCORED data in LAKE, as file 'scored_False.parquet'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>BMI</th>\n",
       "      <th>BP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>S4</th>\n",
       "      <th>S5</th>\n",
       "      <th>S6</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.05</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>255.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.11</td>\n",
       "      <td>251.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>93.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>163.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.02</td>\n",
       "      <td>249.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE   SEX   BMI    BP    S1    S2    S3    S4    S5    S6  result\n",
       "0 0.05  0.05  0.12  0.08 -0.10 -0.10 -0.07 -0.00  0.04 -0.03  255.76\n",
       "1 0.07 -0.04  0.07  0.04  0.02  0.00 -0.04  0.04  0.08  0.11  251.99\n",
       "2 0.06  0.05 -0.03  0.01  0.02  0.02  0.03 -0.04 -0.03 -0.06   93.91\n",
       "3 0.02 -0.04  0.02 -0.02  0.06  0.04  0.03 -0.00  0.04 -0.00  163.61\n",
       "4 0.02 -0.04  0.11  0.06  0.01 -0.03 -0.02  0.02  0.10  0.02  249.65"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 32 - DEPLOY TEST model to TEST webservice (via DEV ws)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p = init_ws() # Authenticate to CLI workspace\n",
    "p.dev_test_prod = \"test\" # This should be read from config  \"GIT-branch-TEST\" then ABOVE get_other_workspace is not needed (but not since only 1 branch-MASTER, we can easily switch)\n",
    "test_ws = p.get_other_workspace(p.dev_test_prod) # Get TEST via DEV workspace/keyvault 6 SP\n",
    "p.init(test_ws) # Automapping from datalake to Azure ML datasets, prints status)\n",
    "\n",
    "# DEPLOY! \n",
    "inference_config, model, best_run = p.get_active_model_inference_config(test_ws)  #   Get from TEST (Roadmap: Get model from DEV workspace)\n",
    "print(\"Found model: {} version {} in TEST\".format(model.name, model.version))\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config) # Deploy to TEST model to TEST AKS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 32 - SCORE TEST webservice (via 1st authenticaion/DEVws)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p = init_ws() # Authenticate via CLI to a workspace (DEV workspace in this case)\n",
    "p.inference_mode = True\n",
    "\n",
    "# GET TEST workspace, PROJECT are already authenticated via \"a\" workspace (DEV, TEST or PROD)\n",
    "test_ws = p.get_other_workspace(\"test\") # Get TEST via DEV workspace/keyvault 6 SP\n",
    "p.dev_test_prod = \"test\"\n",
    "p.init(test_ws) # Automapping from datalake to Azure ML datasets, prints status)\n",
    "\n",
    "\n",
    "# TEST webservice!\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy(\"Y\") # Get the X_test data, ESML knows the SPLIT and LABEL already (due to training)\n",
    "print(tags)\n",
    "\n",
    "caller_user_id = '81965d9c-40ca-4e47-9723-5a608a32a0e4' # Connect the scoring to a caller/user, globally for all rows\n",
    "df = p.call_webservice(test_ws, X_test,caller_user_id,False) # Auto-fetch key from keyvault, and calls the webservice\n",
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# TODO - in Roadmap"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 32 (TODO) - DEPLOY DEV model to TEST webservice (via DEV ws)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "p = init_ws() # Authenticate via CLI to a workspace (DEV workspace in this case)\n",
    "\n",
    "p.dev_test_prod = \"test\" # This should be read from config  \"GIT-branch-TEST\" then ABOVE get_other_workspace is not needed (but not since only 1 branch-MASTER, we can easily switch)\n",
    "test_ws = p.get_other_workspace(p.dev_test_prod) # Get TEST via DEV workspace/keyvault 6 SP\n",
    "p.init(test_ws) # Automapping from datalake to Azure ML datasets, prints status)\n",
    "\n",
    "# DEPLOY! \n",
    "\n",
    "# A DEV to TEST (There is no model with id AutoMLfc209440a6:8 in msft-weu-TEST-eap-proj02_ai-amls)\n",
    "p.dev_test_prod = \"dev\"\n",
    "print(\"Active workspace: (before fetch model) \", p.ws.name)\n",
    "\n",
    "inference_config, model, best_run = p.get_active_model_inference_config(p.ws)  #   Get from DEV\n",
    "print(\"Found model: {} version {} in DEV\".format(model.name, model.version))\n",
    "\n",
    "print(\"Active workspace (before deploy): \", p.ws.name)\n",
    "p.dev_test_prod = \"test\"\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config) # Deploy DEV model to TEST AKS...does this work?\n",
    "\n",
    "# B) TEST to TEST\n",
    "#p.dev_test_prod = \"test\"\n",
    "#inference_config, model, best_run = p.get_active_model_inference_config(test_ws)  #   Get from TEST (Roadmap: Get model from DEV workspace)\n",
    "#print(\"Found model: {} version {} in TEST\".format(model.name, model.version))\n",
    "#service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config) # Deploy to TEST model to TEST AKS"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}