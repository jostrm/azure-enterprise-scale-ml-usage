{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  },
  "interpreter": {
   "hash": "3fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Simulate CLI Auth from MLops"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SDK Version: 1.26.0\n",
      "Inference version: 1\n",
      "\n",
      " - ds01_diabetes\n",
      "projects/project002/03_diabetes_model_reg/inference/1/ds01_diabetes/in/dev/2021/06/08/\n",
      "projects/project002/03_diabetes_model_reg/inference/1/ds01_diabetes/out/bronze/dev/\n",
      "projects/project002/03_diabetes_model_reg/inference/1/ds01_diabetes/out/silver/dev/\n",
      "\n",
      " - ds02_other\n",
      "projects/project002/03_diabetes_model_reg/inference/1/ds02_other/in/dev/2021/06/08/\n",
      "projects/project002/03_diabetes_model_reg/inference/1/ds02_other/out/bronze/dev/\n",
      "projects/project002/03_diabetes_model_reg/inference/1/ds02_other/out/silver/dev/\n",
      " \n",
      "\n",
      "Training GOLD (p.GoldPath)\n",
      "projects/project002/03_diabetes_model_reg/inference/1/gold/dev/\n",
      " \n",
      "\n",
      "[A) USAGE]: to_score_folder, scored_folder, date_folder = p.get_gold_scored_unique_path()\n",
      "A)INFERENCE ONLINE: GOLD to score (example if realtime - today)\n",
      "projects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_22/69fa6839b287490bbc195dd014215a64/\n",
      " \n",
      "\n",
      "A)INFERENCE ONLINE: GOLD scored (example if realtime today)\n",
      "projects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_22/69fa6839b287490bbc195dd014215a64/\n",
      " \n",
      "\n",
      "[B) USAGE]: to_score_folder_batch, scored_folder, date_folder = p.get_gold_scored_unique_path(p.date_scoring_folder)\n",
      "B)INFERENCE BATCH: GOLD to score (example batch, datetime from config)\n",
      "projects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/3c628719e42647d892d8339779fbe399/\n",
      " \n",
      "\n",
      "B)INFERENCE BATCH: GOLD scored (example batch, datetime from config)\n",
      "projects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/3c628719e42647d892d8339779fbe399/\n",
      " \n",
      "\n",
      "C) INFERENCE BATCH (SCENARIO 2): TODAY I scored data from X days AGO  (second datefolder from config - X days ago)\n",
      "projects/project002/03_diabetes_model_reg/inference/1/gold/dev/2021_06_08/3c628719e42647d892d8339779fbe399/2021_06_08/\n",
      "projects/project002/03_diabetes_model_reg/inference/1/scored/dev/2021_06_08/3c628719e42647d892d8339779fbe399/2021_06_08/\n",
      " \n",
      "\n",
      "ENVIRONMENT - DEV, TEST, or PROD?  [USAGE: p.dev_test_prod]\n",
      "ACTIVE ENVIRONMENT = dev\n",
      "ACTIVE subscription = ca0a8c40-b06a-4e4e-8434-63c03a1dee34\n",
      "- MSFT-WEU-EAP_PROJECT02_AI-DEV-RG\n",
      "- msft-weu-DEV-eap-proj02_ai-amls\n",
      "- westeurope\n",
      "- MSFT-WEU-EAP_CMN_AI-DEV-RG\n",
      "Active vNet: msft-weu-dev-cmnai-vnet\n",
      "Active SubNet: \n",
      "[USAGE] for the above: p.vNetForActiveEnvironment()\n",
      "Active Lake (storage account)  msftweudevcmnai2\n",
      "[USAGE] for the above: p.getLakeForActiveEnvironment()\n",
      "AML for docker: True\n"
     ]
    }
   ],
   "source": [
    "import repackage\n",
    "repackage.add(\"../../azure-enterprise-scale-ml/esml/common/\")\n",
    "#sys.path.append(os.path.abspath(\"../../azure-enterprise-scale-ml/esml/common/\"))  # NOQA: E402\n",
    "#repackage.add(\"../../esml/common/\")\n",
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "print(\"SDK Version:\", azureml.core.VERSION)\n",
    "\n",
    "def init_ws():\n",
    "    p = ESMLProject() # self-aware about its config sources\n",
    "\n",
    "    # WRITE ws config - simulate CLI auth with Interactive\n",
    "    cli_auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "    ws, config_name = p.authenticate_workspace_and_write_config(cli_auth)    \n",
    "    # TEST read\n",
    "    ws = p.get_workspace_from_config(cli_auth) # Authenticate to DEV\n",
    "    p.ws = ws\n",
    "    return p\n",
    "    \n",
    "p = init_ws()\n",
    "p.describe()"
   ]
  },
  {
   "source": [
    "# 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "msft-weu-DEV-eap-proj02_ai-amls\nMSFT-WEU-EAP_PROJECT02_AI-DEV-RG\nwesteurope\nca0a8c40-b06a-4e4e-8434-63c03a1dee34\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Copyright (C) Microsoft Corporation. All rights reserved.​\n",
    " ​\n",
    "Microsoft Corporation (“Microsoft”) grants you a nonexclusive, perpetual,\n",
    "royalty-free right to use, copy, and modify the software code provided by us\n",
    "(\"Software Code\"). You may not sublicense the Software Code or any use of it\n",
    "(except to your affiliates and to vendors to perform work on your behalf)\n",
    "through distribution, network access, service agreement, lease, rental, or\n",
    "otherwise. This license does not purport to express any claim of ownership over\n",
    "data you may have shared with Microsoft in the creation of the Software Code.\n",
    "Unless applicable law gives you more rights, Microsoft reserves all other\n",
    "rights not expressly granted herein, whether by implication, estoppel or\n",
    "otherwise. ​\n",
    " ​\n",
    "THE SOFTWARE CODE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS\n",
    "OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "MICROSOFT OR ITS LICENSORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\n",
    "SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,\n",
    "PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR\n",
    "BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER\n",
    "IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "ARISING IN ANY WAY OUT OF THE USE OF THE SOFTWARE CODE, EVEN IF ADVISED OF THE\n",
    "POSSIBILITY OF SUCH DAMAGE.\n",
    "\"\"\"\n",
    "#import repackage\n",
    "#repackage.add(\"../../azure-enterprise-scale-ml/esml/common/\")\n",
    "#import azureml.core\n",
    "#from azureml.core.authentication import AzureCliAuthentication\n",
    "#from esml import ESMLProject\n",
    "#print(\"SDK Version:\", azureml.core.VERSION)\n",
    "\n",
    "#p = ESMLProject.get_project_from_env_command_line() # Alt A)\n",
    "#print(\"ESML environment (dev, test or prod): {}\".format(p.dev_test_prod))\n",
    "#p.describe()\n",
    "#cli_auth = AzureCliAuthentication()\n",
    "#ws, config_name = p.authenticate_workspace_and_write_config(cli_auth) \n",
    "\n",
    "p = init_ws() # Simulates the \"commented code above\"-to authentica and create ESMLProject\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\n",
    "ws = p.ws\n",
    "print(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep=\"\\n\")"
   ]
  },
  {
   "source": [
    "# 21 Bronze 2 Gold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "...\n",
      "..\n",
      "Using GEN2 as Datastore\n",
      "Searching for setting in ESML datalake...\n",
      "ESML in-folder settings override = TRUE \n",
      " - Found settings in the ESML AutoLake  [active_in_folder.json,active_scoring_in_folder.json], to override ArgParse/GIT config with.\n",
      " - TRAIN in date:  2021/01/01\n",
      " - INFERENCE in date: 2021/06/08 and ModelVersion to score with: 1 (0=latest)\n",
      "\n",
      "Inference mode (False = Training mode): False\n",
      "Load data as Datasets....\n",
      "ds01_diabetes\n",
      "..\n",
      "ds02_other\n",
      "..\n",
      "\n",
      "####### Automap & Autoregister - SUCCESS!\n",
      "1) Auto mapped 2 ESML Dataset with registered Azure ML Datasets (potentially all 3: IN,BRONZE, SILVER) in Datastore project002 \n",
      "\n",
      "Dataset 'ds01_diabetes' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "Dataset 'ds02_other' status:\n",
      " - IN_Folder_has_files\n",
      " - BRONZE_Folder_has_files\n",
      " - SILVER_Folder_has_files\n",
      "\n",
      "2) Registered each Dataset with suffixes (_IN, _BRONZE, _SILVER) \n",
      " Tip: Use ESMLProject.Datasets list or .DatasetByName(myDatasetName) to read/write\n",
      "#######\n",
      "..\n",
      "..\n"
     ]
    }
   ],
   "source": [
    "p = init_ws()\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\n",
    "p.init(ws) # Automapping from datalake to Azure ML datasets, prints status\n",
    "\n",
    "# FEATURE ENGINEERING - Bronze 2 Gold - working with Azure ML Datasets with Bronze, Silver, Gold concept\n",
    "esml_dataset = p.DatasetByName(\"ds01_diabetes\") # Get dataset\n",
    "df_bronze = esml_dataset.Bronze.to_pandas_dataframe()\n",
    "p.save_silver(esml_dataset,df_bronze) #Bronze -> Silver\n",
    "\n",
    "# Silver -> Gold\n",
    "df = esml_dataset.Silver.to_pandas_dataframe() \n",
    "df_filtered = df[df.AGE > 0.015] \n",
    "gold_train = p.save_gold(df_filtered)  #Save: Silver -> Gold"
   ]
  },
  {
   "source": [
    "# 22 - TRAIN step"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "from baselayer_azure_ml import AutoMLFactory,azure_metric_regression,azure_metric_classification\n",
    "\n",
    "p = init_ws()\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\n",
    "p.init(ws) # Automapping from datalake to Azure ML datasets, prints status\n",
    "\n",
    "# TRAIN MODEL\n",
    "automl_performance_config = p.get_automl_performance_config() # 1)Get config\n",
    "aml_compute = p.get_training_aml_compute(p.ws) # 2)Get compute, for active environment\n",
    "\n",
    "label = \"Y\"\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # 3) Auto register in Azure (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) \n",
    "automl_config = AutoMLConfig(task = 'regression', # 4) \n",
    "                            primary_metric = azure_metric_regression.MAE, #Note: !MAPE \n",
    "                            compute_target = aml_compute,\n",
    "                            training_data = p.GoldTrain, \n",
    "                            label_column_name = label,\n",
    "                            **automl_performance_config\n",
    "                        )\n",
    "train_as_pipeline = False\n",
    "best_run, fitted_model, experiment = None, None, None # Consistent return values from both AutoML ALTERNATIVES\n",
    "\n",
    "if (train_as_pipeline):\n",
    "    print(\"train_as_pipeline\")\n",
    "    best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) #) 5 Train model\n",
    "else: \n",
    "    print(\"train_as_run\")\n",
    "    best_run, fitted_model, experiment = AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "source": [
    "# 23 - compare scoring\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Example: If new model scores better in DEV, we can promote this to TEST\n",
      "Loading AutoML config settings from: dev\n",
      "targe=source environement. Compare model version in DEV/TEST/PROD with latest registered in same DEV/TEST/PROD workspace (same workspace & subscriptiom comparison)\n",
      "\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.30.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "TARGET is in the same Azure ML Studio workspace as SOURCE, comparing with latest registered model...\n",
      "target_best_run_id AutoML_1cc989cd-81d3-4693-b5a9-b2ae9188302f\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.30.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "New trained model & cached RUN, has TASK_TYPE: regression and Best_Run_id: AutoML_1cc989cd-81d3-4693-b5a9-b2ae9188302f_0\n",
      "Target model & RUN, in Azure ML Studio workspace to compare with, has TASK_TYPE: regression and Best_Run_id: \n",
      "\n",
      "Q: Do we have SCORING DRIFT / CONCEPT DRIFT?\n",
      "Q: Is a model trained on NEW data better? Is the one in production degraded? (not fit for the data it scores - real world changed, other CONCEPT)\n",
      "A: - Lets check. Instead of DataDrift, lets look at actual SCORING on new data (or same data, other code). See if we should PROMOTE newly trained model...\n",
      "\n",
      "New trained model: \n",
      "RMSE (normalized_root_mean_squared_error): 0.25367474015281405\n",
      "MAPE (Mean average Percentage Error): 47.73639492683337\n",
      "MAE (normalized_mean_absolute_error): 0.21601394568522597\n",
      "R2 (r2_score): -0.010634855762826967\n",
      "Spearman (spearman_correlation): -1.0\n",
      "\n",
      "Target model, to compare with; \n",
      "RMSE (normalized_root_mean_squared_error): 0.25367474015281405\n",
      "MAPE (Mean average Percentage Error): 47.73639492683337\n",
      "MAE (normalized_mean_absolute_error): 0.21601394568522597\n",
      "R2 (r2_score): -0.010634855762826967\n",
      "Spearman (spearman_correlation): -1.0\n",
      "\n",
      "Selected metrics, and weights, to be used when comparing for promotion/scoring drift\n",
      "Metric weight: RMSE_promote_weight is 0.0200\n",
      "Metric VALUE (incl. weight) 0.2337 (without weight:  0.2537)\n",
      "\n",
      "Metric weight: R2_promote_weight is -0.0010\n",
      "Metric VALUE (incl. weight) -0.0096 (without weight:  -0.0106)\n",
      "\n",
      "Metric weight: Spearman_promote_weight is -0.0010\n",
      "Metric VALUE (incl. weight) -0.9990 (without weight:  -1.0000)\n",
      "\n",
      "\n",
      "Promote model = True\n",
      "New Model: AutoML1cc989cd80 in environment dev\n",
      "Existing Model: AutoML1cc989cd80 in environment dev\n",
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "model.version 6\n",
      "Model name AutoML1cc989cd80 is registered.\n"
     ]
    }
   ],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory\n",
    "p = init_ws()\n",
    "p.inference_mode = False # We want \"TRAIN\" mode\n",
    "\n",
    "# COMPARE MODEL SCORING - Promote?\n",
    "target_env = \"dev\" # If not set or used, it will automatically test for NEXT environment\n",
    "print(\"Example: If new model scores better in DEV, we can promote this to TEST\")\n",
    "\n",
    "promote, m1_name, r1_id, m2_name, r2_run_id = AutoMLFactory(p).compare_scoring_current_vs_new_model(target_env)\n",
    "\n",
    "print(\"New Model: {} in environment {}\".format(m1_name, p.dev_test_prod))\n",
    "print(\"Existing Model: {} in environment {}\".format(m2_name,target_env))\n",
    "\n",
    "if (promote and p.dev_test_prod == target_env):# Can only register a model in same workspace (test->test) - need to retrain if going from dev->test\n",
    "    AutoMLFactory(p).register_active_model(target_env)\n"
   ]
  },
  {
   "source": [
    "# 31 - deploy to DEV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Environment:\n",
      "dev msft-weu-DEV-eap-proj02_ai-amls\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Loading AutoML config settings from: dev\n",
      "Loading AutoML config settings from: dev\n",
      "WARNING:root:The version of the SDK does not match the version the model was trained on.\n",
      "WARNING:root:The consistency in the result may not be guaranteed.\n",
      "WARNING:root:Package:azureml-automl-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-dataprep, training version:2.15.1, current version:2.13.2\n",
      "Package:azureml-dataprep-native, training version:33.0.0, current version:32.0.0\n",
      "Package:azureml-dataprep-rslex, training version:1.13.0, current version:1.11.2\n",
      "Package:azureml-dataset-runtime, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-defaults, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-interpret, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-pipeline-core, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-telemetry, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-client, training version:1.30.0, current version:1.26.0\n",
      "Package:azureml-train-automl-runtime, training version:1.30.0, current version:1.26.0\n",
      "WARNING:root:Below packages were used for model training but missing in current environment:\n",
      "WARNING:root:Package:azureml-mlflow, training version:1.30.0\n",
      "WARNING:root:Please ensure the version of your local conda dependencies match the version on which your model was trained in order to properly retrieve your model.\n",
      "Deploying model: AutoML1cc989cd80 with verison: 6 to environment: dev with overwrite_endpoint=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "image_build_compute = prj02-m03-dev\n",
      "Found existing AksWebservice endpoint, deleting it, since overwrite=True\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster, esml-dev-prj02, using it.\n",
      "Note: Autoscale_enabled=False, or since aks_dev_test=True in config, autoscaling is automatically shut off, e.g. overridden in config (since not supported) for environment dev\n",
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-22 01:28:43+02:00 Creating Container Registry if not exists.\n",
      "2021-06-22 01:28:43+02:00 Registering the environment.\n",
      "2021-06-22 01:28:44+02:00 Use the existing image.\n",
      "2021-06-22 01:28:46+02:00 Creating resources in AKS.\n",
      "2021-06-22 01:28:46+02:00 Submitting deployment to compute.\n",
      "2021-06-22 01:28:48+02:00 Checking the status of deployment esml-dev-p02-m03-aksapi..\n",
      "2021-06-22 01:29:10+02:00 Checking the status of inference endpoint esml-dev-p02-m03-aksapi.\n",
      "Succeeded\n",
      "AKS service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n",
      "2021-06-21T23:28:55,706924207+00:00 - iot-server/run \n",
      "2021-06-21T23:28:55,710092567+00:00 - rsyslog/run \n",
      "2021-06-21T23:28:55,713865619+00:00 - gunicorn/run \n",
      "rsyslogd: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
      "2021-06-21T23:28:55,728396335+00:00 - nginx/run \n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "/usr/sbin/nginx: /azureml-envs/azureml_9f1639e55483048380059c02b396daba/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-21T23:28:55,812743163+00:00 - iot-server/finish 1 0\n",
      "2021-06-21T23:28:55,814000747+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 40\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Generating new fontManager, this may take some time...\n",
      "Initializing logger\n",
      "2021-06-21 23:28:57,023 | root | INFO | Starting up app insights client\n",
      "2021-06-21 23:28:57,024 | root | INFO | Starting up request id generator\n",
      "2021-06-21 23:28:57,024 | root | INFO | Starting up app insight hooks\n",
      "2021-06-21 23:28:57,024 | root | INFO | Invoking user's init function\n",
      "2021-06-21 23:28:59,228 | azureml.core | WARNING | Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception cannot import name 'RunType'.\n",
      "2021-06-21 23:28:59,473 | root | INFO | Users's init has completed successfully\n",
      "2021-06-21 23:28:59,475 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-06-21 23:28:59,475 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-06-21 23:28:59,476 | root | INFO | Scoring timeout is found from os.environ: 300000 ms\n",
      "2021-06-21 23:29:10,534 | root | INFO | 200\n",
      "127.0.0.1 - - [21/Jun/2021:23:29:10 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "2021-06-21 23:29:21,906 | root | INFO | 200\n",
      "127.0.0.1 - - [21/Jun/2021:23:29:21 +0000] \"GET /swagger.json HTTP/1.0\" 200 2711 \"-\" \"hackney/1.17.4\"\n",
      "\n",
      "Deployed AKS Webservice: esml-dev-p02-m03-aksapi \n",
      "Webservice Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/score \n",
      "Webservice API_Secret are stored in keyvault with name: esml-dev-p02-m03-apisecret \n",
      "Webservice API_URI are stored in keyvault with name: esml-dev-p02-m03-api \n",
      "Webservice Swagger Uri: https://esmlcmn7skp17.westeurope.cloudapp.azure.com:443/api/v1/service/esml-dev-p02-m03-aksapi/swagger.json\n"
     ]
    }
   ],
   "source": [
    "p = init_ws()\n",
    "#p.init(ws) # Automapping from datalake to Azure ML datasets, prints status\n",
    "\n",
    "print(\"Environment:\")\n",
    "print(p.dev_test_prod,p.ws.name)\n",
    "\n",
    "# DEPLOY!\n",
    "inference_config, model, best_run = p.get_active_model_inference_config(p.ws) #  AutoML support \n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config)"
   ]
  },
  {
   "source": [
    "# 31 - TEST DEV webservice"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using GEN2 as Datastore\n",
      "M03_GOLD_VALIDATE : (37, 11)\n",
      "X_test  (37, 10)\n",
      "y_test  (37,)\n",
      "{'split_percentage': '0.2', 'label': 'Y', 'model': '03_diabetes_model_reg'}\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Note: Fetching keys automatically via workspace keyvault.\n",
      "Saving scoring to lake for project folder project002 and inference_model_version: 6 ...\n",
      "...\n",
      "..\n",
      "\n",
      "Saved DATA to score successfully in LAKE, as file 'to_score_False.parquet'\n",
      "..\n",
      "Saved SCORED data in LAKE, as file 'scored_False.parquet'\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   AGE   SEX   BMI    BP    S1    S2    S3    S4    S5    S6  result\n",
       "0 0.05  0.05  0.12  0.08 -0.10 -0.10 -0.07 -0.00  0.04 -0.03  255.76\n",
       "1 0.07 -0.04  0.07  0.04  0.02  0.00 -0.04  0.04  0.08  0.11  251.99\n",
       "2 0.06  0.05 -0.03  0.01  0.02  0.02  0.03 -0.04 -0.03 -0.06   93.91\n",
       "3 0.02 -0.04  0.02 -0.02  0.06  0.04  0.03 -0.00  0.04 -0.00  163.61\n",
       "4 0.02 -0.04  0.11  0.06  0.01 -0.03 -0.02  0.02  0.10  0.02  249.65"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>SEX</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>result</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.05</td>\n      <td>0.05</td>\n      <td>0.12</td>\n      <td>0.08</td>\n      <td>-0.10</td>\n      <td>-0.10</td>\n      <td>-0.07</td>\n      <td>-0.00</td>\n      <td>0.04</td>\n      <td>-0.03</td>\n      <td>255.76</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.07</td>\n      <td>-0.04</td>\n      <td>0.07</td>\n      <td>0.04</td>\n      <td>0.02</td>\n      <td>0.00</td>\n      <td>-0.04</td>\n      <td>0.04</td>\n      <td>0.08</td>\n      <td>0.11</td>\n      <td>251.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.06</td>\n      <td>0.05</td>\n      <td>-0.03</td>\n      <td>0.01</td>\n      <td>0.02</td>\n      <td>0.02</td>\n      <td>0.03</td>\n      <td>-0.04</td>\n      <td>-0.03</td>\n      <td>-0.06</td>\n      <td>93.91</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.02</td>\n      <td>-0.04</td>\n      <td>0.02</td>\n      <td>-0.02</td>\n      <td>0.06</td>\n      <td>0.04</td>\n      <td>0.03</td>\n      <td>-0.00</td>\n      <td>0.04</td>\n      <td>-0.00</td>\n      <td>163.61</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.02</td>\n      <td>-0.04</td>\n      <td>0.11</td>\n      <td>0.06</td>\n      <td>0.01</td>\n      <td>-0.03</td>\n      <td>-0.02</td>\n      <td>0.02</td>\n      <td>0.10</td>\n      <td>0.02</td>\n      <td>249.65</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "p = init_ws()\n",
    "p.inference_mode = True \n",
    "p.connect_to_lake() # To be able to also SAVE scoring autmatically\n",
    "\n",
    "# Get TEST-data\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy() # Get  X_test data, ESML knowsSPLIT and LABEL already \n",
    "print(tags)\n",
    "\n",
    "df = p.call_webservice(p.ws, X_test,False) # Auto-fetch key from keyvault, and calls the webservice\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# 32 - DEPLOY TEST model to TEST webservice (via DEV ws)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = init_ws() # Authenticate to CLI workspace\n",
    "p.dev_test_prod = \"test\" # This should be read from config  \"GIT-branch-TEST\" then ABOVE get_other_workspace is not needed (but not since only 1 branch-MASTER, we can easily switch)\n",
    "test_ws = p.get_other_workspace(p.dev_test_prod) # Get TEST via DEV workspace/keyvault 6 SP\n",
    "p.init(test_ws) # Automapping from datalake to Azure ML datasets, prints status)\n",
    "\n",
    "# DEPLOY! \n",
    "inference_config, model, best_run = p.get_active_model_inference_config(test_ws)  #   Get from TEST (Roadmap: Get model from DEV workspace)\n",
    "print(\"Found model: {} version {} in TEST\".format(model.name, model.version))\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config) # Deploy to TEST model to TEST AKS"
   ]
  },
  {
   "source": [
    "# 32 - SCORE TEST webservice (via 1st authenticaion/DEVws)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = init_ws() # Authenticate via CLI to a workspace (DEV workspace in this case)\n",
    "p.inference_mode = True\n",
    "\n",
    "# GET TEST workspace, PROJECT are already authenticated via \"a\" workspace (DEV, TEST or PROD)\n",
    "test_ws = p.get_other_workspace(\"test\") # Get TEST via DEV workspace/keyvault 6 SP\n",
    "p.dev_test_prod = \"test\"\n",
    "p.init(test_ws) # Automapping from datalake to Azure ML datasets, prints status)\n",
    "\n",
    "\n",
    "# TEST webservice!\n",
    "X_test, y_test, tags = p.get_gold_validate_Xy(\"Y\") # Get the X_test data, ESML knows the SPLIT and LABEL already (due to training)\n",
    "print(tags)\n",
    "\n",
    "caller_user_id = '81965d9c-40ca-4e47-9723-5a608a32a0e4' # Connect the scoring to a caller/user, globally for all rows\n",
    "df = p.call_webservice(test_ws, X_test,caller_user_id,False) # Auto-fetch key from keyvault, and calls the webservice\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "# TODO - in Roadmap"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 32 (TODO) - DEPLOY DEV model to TEST webservice (via DEV ws)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = init_ws() # Authenticate via CLI to a workspace (DEV workspace in this case)\n",
    "\n",
    "p.dev_test_prod = \"test\" # This should be read from config  \"GIT-branch-TEST\" then ABOVE get_other_workspace is not needed (but not since only 1 branch-MASTER, we can easily switch)\n",
    "test_ws = p.get_other_workspace(p.dev_test_prod) # Get TEST via DEV workspace/keyvault 6 SP\n",
    "p.init(test_ws) # Automapping from datalake to Azure ML datasets, prints status)\n",
    "\n",
    "# DEPLOY! \n",
    "\n",
    "# A DEV to TEST (There is no model with id AutoMLfc209440a6:8 in msft-weu-TEST-eap-proj02_ai-amls)\n",
    "p.dev_test_prod = \"dev\"\n",
    "print(\"Active workspace: (before fetch model) \", p.ws.name)\n",
    "\n",
    "inference_config, model, best_run = p.get_active_model_inference_config(p.ws)  #   Get from DEV\n",
    "print(\"Found model: {} version {} in DEV\".format(model.name, model.version))\n",
    "\n",
    "print(\"Active workspace (before deploy): \", p.ws.name)\n",
    "p.dev_test_prod = \"test\"\n",
    "service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config) # Deploy DEV model to TEST AKS...does this work?\n",
    "\n",
    "# B) TEST to TEST\n",
    "#p.dev_test_prod = \"test\"\n",
    "#inference_config, model, best_run = p.get_active_model_inference_config(test_ws)  #   Get from TEST (Roadmap: Get model from DEV workspace)\n",
    "#print(\"Found model: {} version {} in TEST\".format(model.name, model.version))\n",
    "#service,api_uri, kv_aks_api_secret= p.deploy_automl_model_to_aks(model,inference_config) # Deploy to TEST model to TEST AKS"
   ]
  }
 ]
}