{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always run thic CELL below\n",
    "- To attach ESML controlplane to your project\n",
    "- To point at `template-data` for the pipelinbe to know the schema of data\n",
    "- To init the ESMLPieplinefactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "\n",
      " ---- Q: WHICH files are generated as templates, for you to EDIT? ---- \n",
      "A: These files & locations:\n",
      "File to EDIT (step: IN_2_SILVER_1): ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds01_titanic.py\n",
      "File to EDIT (step: IN_2_SILVER_2): ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds02_haircolor.py\n",
      "File to EDIT (step: IN_2_SILVER_3): ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds03_housing.py\n",
      "File to EDIT (step: IN_2_SILVER_4): ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds04_lightsaber.py\n",
      "File to EDIT (step: SILVER_MERGED_2_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M10/silver_merged_2_gold.py\n",
      "File to EDIT (step: SCORING_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M10/scoring_gold.py\n",
      "File to EDIT (step: TRAIN_SPLIT_AND_REGISTER): ../../../2_A_aml_pipeline/4_inference/batch/M10/train_split_and_register.py\n",
      "File to EDIT (step: TRAIN_MANUAL): ../../../2_A_aml_pipeline/4_inference/batch/M10/train_manual.py\n",
      "File to EDIT a lot (reference in step-scripts Custom code): ../../../2_A_aml_pipeline/4_inference/batch/M10/your_code/your_custom_code.py\n",
      "\n",
      " ---- WHAT model to SCORE with, & WHAT data 'date_folder'? ---- \n",
      "InferenceModelVersion (model version to score with): 1\n",
      "Date_scoring_folder (data to score) : 1000-01-01 10:35:01.243860\n",
      "ESML environment: dev\n",
      "Inference mode (self.batch_pipeline_parameters[4]): 1\n",
      "\n",
      " ---- ESML Datalake locations: ESML Datasets (IN-data) ---- \n",
      "Name (lake folder): ds01_titanic and AzureName IN: M10_ds01_titanic_inference_IN\n",
      "IN projects/project002/10_titanic_model_clas/inference/1/ds01_titanic/in/dev/2021/06/08/\n",
      "Bronze projects/project002/10_titanic_model_clas/inference/1/ds01_titanic/out/bronze/dev/\n",
      "Silver projects/project002/10_titanic_model_clas/inference/1/ds01_titanic/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds02_haircolor and AzureName IN: M10_ds02_haircolor_inference_IN\n",
      "IN projects/project002/10_titanic_model_clas/inference/1/ds02_haircolor/in/dev/2021/06/08/\n",
      "Bronze projects/project002/10_titanic_model_clas/inference/1/ds02_haircolor/out/bronze/dev/\n",
      "Silver projects/project002/10_titanic_model_clas/inference/1/ds02_haircolor/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds03_housing and AzureName IN: M10_ds03_housing_inference_IN\n",
      "IN projects/project002/10_titanic_model_clas/inference/1/ds03_housing/in/dev/2021/06/08/\n",
      "Bronze projects/project002/10_titanic_model_clas/inference/1/ds03_housing/out/bronze/dev/\n",
      "Silver projects/project002/10_titanic_model_clas/inference/1/ds03_housing/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds04_lightsaber and AzureName IN: M10_ds04_lightsaber_inference_IN\n",
      "IN projects/project002/10_titanic_model_clas/inference/1/ds04_lightsaber/in/dev/2021/06/08/\n",
      "Bronze projects/project002/10_titanic_model_clas/inference/1/ds04_lightsaber/out/bronze/dev/\n",
      "Silver projects/project002/10_titanic_model_clas/inference/1/ds04_lightsaber/out/silver/dev/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "from baselayer_azure_ml_pipeline import ESMLPipelineFactory, esml_pipeline_types\n",
    "\n",
    "p = ESMLProject()\n",
    "p.inference_mode = True\n",
    "p.active_model = 11 # 10=titanic , 11=Diabetes\n",
    "p_factory = ESMLPipelineFactory(p)\n",
    "\n",
    "scoring_date = '1000-01-01 10:35:01.243860' # \n",
    "p_factory.batch_pipeline_parameters[1].default_value = scoring_date # overrides ESMLProject.date_scoring_folder.\n",
    "p_factory.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN_2_GOLD_SCORING\n",
    "- Full ML-workflow: If you want to refine data from IN to GOLD, and SCORE model on GOLD, saves SCORED_GOLD in datalake\n",
    "- Scenario: You want MLOps and full automation, ESMLPipelineFactory starting from Azure Data factory, and calling this genereated Azure ML Pipeline. \n",
    "    - Pipeline saving data automatically using the enterprise datalake/ESML AutoLake and ESML SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creates template step_files.py for user to edit at:\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds01_titanic.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds02_haircolor.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds03_housing.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/in2silver_ds04_lightsaber.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/silver_merged_2_gold.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/scoring_gold.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/train_split_and_register.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/train_manual.py\n",
      "Edit at ../../../2_A_aml_pipeline/4_inference/batch/M10/your_code/your_custom_code.py\n",
      "Using GEN2 as Datastore\n",
      "use_project_sp_2_mount: True\n",
      "ESML will auto-create a compute...\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster p002-m10weu-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = p002-m10weu-dev\n",
      "Reusing existing compute...\n",
      "Reusing existing compute...\n",
      "Reusing existing compute...\n",
      "create_gold_to_score_step: inference_mode=True\n"
     ]
    }
   ],
   "source": [
    "## BUILD\n",
    "p_factory.create_dataset_scripts_from_template(overwrite_if_exists=True) # Do this once, then edit them manually. overwrite_if_exists=False is DEFAULT\n",
    "batch_pipeline = p_factory.create_batch_pipeline(esml_pipeline_types.IN_2_GOLD_SCORING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execute_pipeline (scoring): Inference_mode: 1\n",
      "Created step IN 2 SILVER - ds01_titanic [eb669812][55925d81-1501-48a7-b414-c662e374b1fb], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds02_haircolor [1ddc6965][48803185-7e76-41c5-b8fc-4e9dd92aab9e], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds03_housing [6f6f2157][61949003-ff39-4c84-87fa-66e86d4140bb], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds04_lightsaber [0fee0835][c77ba037-ca83-447d-891d-c71bdd419f74], (This step will run and generate new outputs)\n",
      "Created step SILVER MERGED 2 GOLD [e569304b][e963fe5b-1c97-45c1-bcc2-a759b8376d80], (This step will run and generate new outputs)\n",
      "Created step SCORING GOLD [f4b5eb80][8554d554-6efc-493b-8b0e-82637842eeed], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun f1efb39a-c578-4062-828b-1037bb7164c0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f1efb39a-c578-4062-828b-1037bb7164c0?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/abc-def-esml-project002-weu-DEV-004-rg/workspaces/aml-prj002-weu-DEV-003&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution!\n",
      "PipelineRunId: f1efb39a-c578-4062-828b-1037bb7164c0\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f1efb39a-c578-4062-828b-1037bb7164c0?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/abc-def-esml-project002-weu-DEV-004-rg/workspaces/aml-prj002-weu-DEV-003&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Canceled'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN\n",
    "pipeline_run = p_factory.execute_pipeline(batch_pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_6\n",
      "pub_pipe.id 01274209-95e8-4ffb-9b95-9bfb1c865b28\n",
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "pub_pipe.id cb6e1ef3-ddf2-483c-964e-bc6ba02c610f\n",
      "pub_pipe.name 10_titanic_model_clas_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "pub_pipe.id 6c3c51e9-df26-4373-ae37-0a31a3616ec0\n"
     ]
    }
   ],
   "source": [
    "# PUBLISH\n",
    "published_pipeline, endpoint = p_factory.publish_pipeline(batch_pipeline,\"_1\") # \"_1\" is optional    to create a NEW pipeline with 0 history, not ADD version to existing pipe & endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info - to use  in Azure data factory: `published_pipeline.id` (if private Azure ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\n",
      "- Endpoint ID\n",
      "Endpoint ID:  6c3c51e9-df26-4373-ae37-0a31a3616ec0\n",
      "Endpoint Name:  10_titanic_model_clas_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "Experiment name:  10_titanic_model_clas_pipe_IN_2_GOLD_SCORING\n",
      "In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\n",
      "-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0a3ffd65-f1e2-4705-8fd0-681e4d16fbe4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\") \n",
    "print (\"- Endpoint ID\")\n",
    "print(\"Endpoint ID:  {}\".format(endpoint.id))\n",
    "print(\"Endpoint Name:  {}\".format(endpoint.name))\n",
    "print(\"Experiment name:  {}\".format(p_factory.experiment_name))\n",
    "\n",
    "print(\"In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\")\n",
    "print(\"-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\")\n",
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2f0f778a4495e689b30073b7a599e6a826d304e8985d11475b75364c935a444d"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 ('azure_automl_esml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
