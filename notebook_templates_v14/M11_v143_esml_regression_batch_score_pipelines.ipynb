{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Always run thic CELL below\n",
    "- To attach ESML controlplane to your project\n",
    "- To point at `template-data` for the pipelinbe to know the schema of data\n",
    "- To init the ESMLPieplinefactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using lake_settings.json with ESML version 1.4 - Models array support including LABEL\n",
      "\n",
      " ---- Q: WHICH files are generated as templates, for you to EDIT? ---- \n",
      "A: These files & locations:\n",
      "File to EDIT (step: IN_2_SILVER_1): ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds01_diabetes.py\n",
      "File to EDIT (step: IN_2_SILVER_2): ../../../2_A_aml_pipeline/4_inference/batch/M11/in2silver_ds02_other.py\n",
      "File to EDIT (step: SILVER_MERGED_2_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M11/silver_merged_2_gold.py\n",
      "File to EDIT (step: SCORING_GOLD): ../../../2_A_aml_pipeline/4_inference/batch/M11/scoring_gold.py\n",
      "File to EDIT (step: TRAIN_SPLIT_AND_REGISTER): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_split_and_register.py\n",
      "File to EDIT (step: TRAIN_MANUAL): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_manual.py\n",
      "File to EDIT (step: TRAIN_AUTOML): ../../../2_A_aml_pipeline/4_inference/batch/M11/train_post_automl_step.py\n",
      "File to EDIT a lot (reference in step-scripts Custom code): ../../../2_A_aml_pipeline/4_inference/batch/M11/your_code/your_custom_code.py\n",
      "\n",
      " ---- WHAT model to SCORE with, & WHAT data 'date_folder'? ---- \n",
      "InferenceModelVersion (model version to score with): 1\n",
      "Date_scoring_folder (data to score) : 1000-01-01 10:35:01.243860\n",
      "ESML environment: dev\n",
      "Inference mode (self.batch_pipeline_parameters[4]): 1\n",
      "\n",
      " ---- ESML Datalake locations: ESML Datasets (IN-data) ---- \n",
      "Name (lake folder): ds01_diabetes and AzureName IN: M11_ds01_diabetes_inference_IN\n",
      "IN projects/project002/11_diabetes_model_reg/inference/1/ds01_diabetes/in/dev/2021/06/08/\n",
      "Bronze projects/project002/11_diabetes_model_reg/inference/1/ds01_diabetes/out/bronze/dev/\n",
      "Silver projects/project002/11_diabetes_model_reg/inference/1/ds01_diabetes/out/silver/dev/\n",
      "\n",
      "Name (lake folder): ds02_other and AzureName IN: M11_ds02_other_inference_IN\n",
      "IN projects/project002/11_diabetes_model_reg/inference/1/ds02_other/in/dev/2021/06/08/\n",
      "Bronze projects/project002/11_diabetes_model_reg/inference/1/ds02_other/out/bronze/dev/\n",
      "Silver projects/project002/11_diabetes_model_reg/inference/1/ds02_other/out/silver/dev/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../azure-enterprise-scale-ml/esml/common/\")\n",
    "from esml import ESMLProject\n",
    "from baselayer_azure_ml_pipeline import ESMLPipelineFactory, esml_pipeline_types\n",
    "\n",
    "p = ESMLProject()\n",
    "p.inference_mode = True\n",
    "p.active_model = 11 # 10=titanic , 11=Diabetes\n",
    "p_factory = ESMLPipelineFactory(p)\n",
    "\n",
    "scoring_date = '1000-01-01 10:35:01.243860' # \n",
    "p_factory.batch_pipeline_parameters[1].default_value = scoring_date # overrides ESMLProject.date_scoring_folder.\n",
    "p_factory.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN_2_GOLD_SCORING\n",
    "- 1) Generate code files\n",
    "- 2) Build pipepline, with the ESML oneliner, which also will upload the snapshot folder and code together with the Azure ML pipeline steps\n",
    "- 3) Run the pipeline. Smoke testing, see that it works\n",
    "- 4) IF it works, Publish the pipeline, or else, edit the code files or configuration, retry step 2 and 3.\n",
    "- 5) Print the pipeline_id, that is essential to use from Azure Data factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genereate code files, to be edited later.\n",
    "p_factory.create_dataset_scripts_from_template(overwrite_if_exists=False) # Do this once, then edit them manually. overwrite_if_exists=False is DEFAULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did NOT overwrite script-files with template-files such as 'scoring_gold.py', since overwrite_if_exists=False\n",
      "Using GEN2 as Datastore\n",
      "ESML will auto-create a compute...\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Using a model specific cluster, per configuration in project specific settings, (the integer of 'model_number' is the base for the name)\n",
      "Note: OVERRIDING enterprise performance settings with project specifics. (to change, set flag in 'dev_test_prod_settings.json' -> override_enterprise_settings_with_model_specific=False)\n",
      "Found existing cluster p02-m11weu-dev for project and environment, using it.\n",
      "Succeeded\n",
      "AmlCompute wait for completion finished\n",
      "\n",
      "Minimum number of nodes requested have been provisioned\n",
      "image_build_compute = p02-m11weu-dev\n",
      "Reusing existing compute...\n",
      "create_gold_to_score_step: inference_mode=True\n"
     ]
    }
   ],
   "source": [
    "## BUILD pipeline,\n",
    "batch_pipeline = p_factory.create_batch_pipeline(esml_pipeline_types.IN_2_GOLD_SCORING) # Scoring\n",
    "# ...which uses the BEST trained model, upload the genereated python scripts, uploads your custom code and ESML runtime, to Azure embedded in the pipeline, using Dockerized image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execute_pipeline (scoring): Inference_mode: 1\n",
      "-Scoring data, default value 1000-01-01 10:35:01.243860\n",
      "Created step IN 2 SILVER - ds01_diabetes [50a68622][61116429-a69b-4767-8cd1-67d53c3bedd9], (This step will run and generate new outputs)\n",
      "Created step IN 2 SILVER - ds02_other [d8161219][cbe5292f-1d3d-445b-a33d-79feba6a9a2e], (This step will run and generate new outputs)\n",
      "Created step SILVER MERGED 2 GOLD [9ded6851][83b842f1-5866-4606-8224-53b4c64fb6ef], (This step will run and generate new outputs)\n",
      "Created step SCORING GOLD [a1c16d92][62f97459-0b37-40df-9fbd-bd830bac0f93], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun b5e57980-770c-4d77-afb5-b98c92422539\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b5e57980-770c-4d77-afb5-b98c92422539?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "Pipeline submitted for execution!\n",
      " ### \n",
      "PipelineRunId: b5e57980-770c-4d77-afb5-b98c92422539\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/b5e57980-770c-4d77-afb5-b98c92422539?wsid=/subscriptions/ca0a8c40-b06a-4e4e-8434-63c03a1dee34/resourcegroups/MSFT-WEU-EAP_PROJECT02_AI-DEV-RG/workspaces/msft-weu-DEV-eap-proj02_ai-amls&tid=72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RUN\n",
    "pipeline_run = p_factory.execute_pipeline(batch_pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_6\n",
      "pub_pipe.id 01274209-95e8-4ffb-9b95-9bfb1c865b28\n",
      "pub_pipe.name 11_diabetes_model_reg_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "pub_pipe.id cb6e1ef3-ddf2-483c-964e-bc6ba02c610f\n",
      "pub_pipe.name 10_titanic_model_clas_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "pub_pipe.id 6c3c51e9-df26-4373-ae37-0a31a3616ec0\n"
     ]
    }
   ],
   "source": [
    "# PUBLISH\n",
    "published_pipeline, endpoint = p_factory.publish_pipeline(batch_pipeline,\"_1\") # \"_1\" is optional    to create a NEW pipeline with 0 history, not ADD version to existing pipe & endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get info - to use  in Azure data factory: `published_pipeline.id` (if private Azure ML workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\n",
      "- Endpoint ID\n",
      "Endpoint ID:  6c3c51e9-df26-4373-ae37-0a31a3616ec0\n",
      "Endpoint Name:  10_titanic_model_clas_pipe_IN_2_GOLD_SCORING_EP_1\n",
      "Experiment name:  10_titanic_model_clas_pipe_IN_2_GOLD_SCORING\n",
      "In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\n",
      "-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0a3ffd65-f1e2-4705-8fd0-681e4d16fbe4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"2) Fetch scored data: Below needed for Azure Data factory PIPELINE activity (Pipeline OR Endpoint. Choose the latter\") \n",
    "print (\"- Endpoint ID\")\n",
    "print(\"Endpoint ID:  {}\".format(endpoint.id))\n",
    "print(\"Endpoint Name:  {}\".format(endpoint.name))\n",
    "print(\"Experiment name:  {}\".format(p_factory.experiment_name))\n",
    "\n",
    "print(\"In AZURE DATA FACTORY - This is the ID you need, if using PRIVATE LINK, private Azure ML workspace.\")\n",
    "print(\"-You need PIPELINE id, not pipeline ENDPOINT ID ( since cannot be chosen in Azure data factory if private Azure ML)\")\n",
    "published_pipeline.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('azure_automl_esml_v143')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "74c5b99301bc00796667a0057263c7bfaf21b551f0f69d6227e2067b2db9e406"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
