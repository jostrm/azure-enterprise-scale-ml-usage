{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3612jvsc74a57bd03fec2c5a411dce07235ef28c8752b6cecf1f94423de7e7c24e62fc38b1bc47de",
   "display_name": "Python 3.6.12 64-bit ('azure_automl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# ESML - accelerator: Quick DEMO\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"../azure-enterprise-scale-ml/esml/common/\"))  # NOQA: E402\n",
    "from esml import ESMLDataset, ESMLProject\n",
    "p = ESMLProject() # Will search in ROOT for your copied SETTINGS folder '../../../settings', you should copy template settings from '../settings'\n",
    "#p = ESMLProject(True) # Demo settings, will search in internal TEMPLATE SETTINGS folder '../settings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p.dev_test_prod = \"dev\"\n",
    "p.describe()"
   ]
  },
  {
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "auth = InteractiveLoginAuthentication(tenant_id = p.tenant)\n",
    "ws = Workspace.get(name = p.workspace_name,subscription_id = p.subscription_id,resource_group = p.resource_group,auth=auth)\n",
    "ws.write_config(path=\".\", file_name=\"../../ws_config.json\")\n",
    "\n",
    "ws = Workspace.from_config(\"../ws_config.json\") # Reads config.json "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# 2) ESML will Automap and Autoregister Azure ML Datasets - IN, SILVER, BRONZE, GOLD\n",
    "- `Automap` and `Autoregister` Azure ML Datasets as: `IN, SILVER, BRONZE, GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "ws, config_name = p.authenticate_workspace_and_write_config()\n",
    "ws = p.get_workspace_from_config()\n",
    "ws.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Are we in R&D state (no dataset versioning) = {}\".format(p.rnd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.unregister_all_datasets(ws) # DEMO purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datastore = p.init(ws)"
   ]
  },
  {
   "source": [
    "# 3) IN->`BRONZE->SILVER`->Gold\n",
    "- Create dataset from PANDAS - Save to SILVER"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "ds = p.DatasetByName(\"ds01_diabetes\")\n",
    "df = ds.Bronze.to_pandas_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "source": [
    "## 3) BRONZE-SILVER (EDIT rows & SAVE)\n",
    "- Test change rows, same structure = new version (and new file added)\n",
    "- Note: not earlier files in folder are removed. They are needed for other \"versions\". \n",
    "- Expected: For 3 files: New version, 997 rows: 2 older files=627 + 1 new file=370\n",
    "- Expected (if we delete OLD files): New version, with less rows. 370 instead of 997"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df[df.AGE > 0.015]\n",
    "print(df.shape[0], df_filtered.shape[0])"
   ]
  },
  {
   "source": [
    "## 3a) Save `SILVER` ds01_diabetes"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_silver = p.save_silver(p.DatasetByName(\"ds01_diabetes\"),df_filtered)\n",
    "aml_silver.name"
   ]
  },
  {
   "source": [
    "### COMPARE `BRONZE vs SILVER`\n",
    "- Compare and validate the feature engineering"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds01 = p.DatasetByName(\"ds01_diabetes\")\n",
    "bronze_rows = ds01.Bronze.to_pandas_dataframe().shape[0]\n",
    "silver_rows = ds01.Silver.to_pandas_dataframe().shape[0]\n",
    "\n",
    "print(\"Bronze: {}\".format(bronze_rows)) # Expected 442 rows\n",
    "print(\"Silver: {}\".format(silver_rows)) # Expected 185 rows (filtered)\n",
    "\n",
    "assert bronze_rows == 442,\"BRONZE Should have 442 rows to start with, but is {}\".format(bronze_rows)\n",
    "assert silver_rows == 185,\"SILVER should have 185 after filtering, but is {}\".format(silver_rows)"
   ]
  },
  {
   "source": [
    "## 3b) Save  `BRONZE â†’  SILVER` ds02_other"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_edited = p.DatasetByName(\"ds02_other\").Silver.to_pandas_dataframe()\n",
    "ds02_silver = p.save_silver(p.DatasetByName(\"ds02_other\"),df_edited)\n",
    "ds02_silver.name"
   ]
  },
  {
   "source": [
    "## 3c) Merge all `SILVERS -> then save GOLD`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = ds01.Silver.to_pandas_dataframe()\n",
    "df_02 = ds02_silver.to_pandas_dataframe()\n",
    "df_gold1_join = df_01.join(df_02) # left join -> NULL on df_02\n",
    "print(\"Diabetes shape: \", df_01.shape)\n",
    "print(df_gold1_join.shape)"
   ]
  },
  {
   "source": [
    "# Save `GOLD` v1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.rnd=False # Allow versioning on DATASETS, to have lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_gold_v1 = p.save_gold(df_gold1_join)"
   ]
  },
  {
   "source": [
    "### 3c) Ops! \"faulty\" GOLD - too many features"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p.Gold.to_pandas_dataframe().shape) # 19 features...I want 11"
   ]
  },
  {
   "source": [
    "print(\"Are we in RnD phase? Or do we have 'versioning on datasets=ON'\")\n",
    "print(\"RnD phase = {}\".format(p.rnd))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Save `GOLD` v2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets just go with features from ds01\n",
    "ds_gold_v1 = p.save_gold(df_01)"
   ]
  },
  {
   "source": [
    "# Get `GOLD` by version"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "gold_1 = p.get_gold_version(1)\n",
    "gold_1.to_pandas_dataframe().shape # (185, 19)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_2 = p.get_gold_version(2)\n",
    "gold_2.to_pandas_dataframe().shape # (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.Gold.to_pandas_dataframe().shape # Latest version (185, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01_filtered = df_01[df_01.AGE > 0.03807]\n",
    "ds_gold_v1 = p.save_gold(df_01_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_2 = p.get_gold_version(3) # sliced, from latest version\n",
    "gold_2.to_pandas_dataframe().shape # (113, 11)"
   ]
  },
  {
   "source": [
    "# TRAIN - `AutoMLFactory + ComputeFactory`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baselayer_azure_ml import AutoMLFactory, ComputeFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod = \"test\"\n",
    "print(\"what environment are we targeting? =  {}\".format(p.dev_test_prod)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.dev_test_prod = \"dev\"\n",
    "automl_performance_config = p.get_automl_performance_config()\n",
    "automl_performance_config"
   ]
  },
  {
   "source": [
    "# Get `COMPUTE` for current `ENVIRONMENT`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aml_compute = p.get_training_aml_compute(ws)"
   ]
  },
  {
   "source": [
    "# `TRAIN` model -> See other notebook `esml_howto_2_train.ipynb`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.train.automl import AutoMLConfig\n",
    "from baselayer_azure_ml import azure_metric_regression\n",
    "\n",
    "label = \"Y\"\n",
    "train_6, validate_set_2, test_set_2 = p.split_gold_3(0.6,label) # Auto-registerin AZURE (M03_GOLD_TRAIN | M03_GOLD_VALIDATE | M03_GOLD_TEST) # Alt: train,testv= p.Gold.random_split(percentage=0.8, seed=23)\n",
    "automl_config = AutoMLConfig(task = 'regression',\n",
    "                             primary_metric = azure_metric_regression.MAE,\n",
    "                             experiment_exit_score = '0.208', # DEMO purpose\n",
    "                             compute_target = aml_compute,\n",
    "                             training_data = p.GoldTrain, # is 'train_6' pandas dataframe, but as an Azure ML Dataset\n",
    "                             label_column_name = label,\n",
    "                             **automl_performance_config\n",
    "                            )\n",
    "\n",
    "via_pipeline = False\n",
    "best_run, fitted_model, experiment = AutoMLFactory(p).train_pipeline(automl_config) if via_pipeline else AutoMLFactory(p).train_as_run(automl_config)"
   ]
  },
  {
   "source": [
    "# END"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# ESML - accelerator\n",
    "\n",
    "## PROJECT + DATA CONCEPTS + ENTERPRISE Datalake Design + DEV->PROD MLOps\n",
    "- `1)ESML Project`: The ONLY thing you need to remember is your `Project number` (and `BRONZE, SILVER, GOLD` concept )\n",
    "    - ProjectNo=4 have a list of all your datasets as ESMLDatasets. (Well you need to provide names for them also: \"mydata01\", \"mydata02\" - but thats it)\n",
    "- `2)Lakedesign & Roles`: Bronze, silver, gold + IN and date folders\n",
    "    - Benefits: Physical datalake design!  onnected to Azure ML Workspace, with autoregistration of `Azure ML Datasets`\n",
    "    - `Role 1`: `Data ingestion team` only need to care about 1 thing - onboard data to `IN-folder`, in .CSV format\n",
    "        - `Auto parquet-conversion` from `IN` folder (.CSV) to `OUT`/BRONZE/bronze.PARQUET \n",
    "    - `Role 2`: `Data scientists` only need to care about 3 things (R/W): `BRONZE, SILVER, GOLD` datasets, all in .PARQUET format\n",
    "    - How? The ESML project will `Automap` and `Autoregister` Azure ML Datasets - `IN, SILVER, BRONZE, GOLD`\n",
    "- `2a) R&D  VS Production phase`: \"Latest data\" VS versioning on Datasets and datefolders  \n",
    "    - Benefits \"R&D mode\": Faster RnD phase to onboard and refresh data easy. Also fast \"flip-switch\" to production\n",
    "    - How? `ESMLDataset is context self aware` - knows when it is used in TRAIN or INFERENCE pipeline\n",
    "- `2b) TRAIN vs INFERENCE` versions</u> `Reuse (Bronze->Silver->Gold) pipepline`, for both TRAIN preprocessing, and INFERENCE \n",
    "    - Benefits: Inference with different MODEL version, on data from the same day/time, (to compare scoring etc)\n",
    "    - How? ESMLDataset have context self awareness, and `knows WHERE and HOW to load/save data`\n",
    "- `2c) BATCH CONFIG`: Turn on/off features on ALL datasets\n",
    "    - Accelerate setup: `Datadrift, Time series traits, Smart noise, etc`\n",
    "    - Share refined data back to its \"origin/non-projectbased structure\" easy: \n",
    "        - ESMLProject.ShareBack(ds.Silver)\n",
    "    - How? ESMProject controls all ESMDatasets, in a uniform way\n",
    "## ENTERPRISE Deployment of Models & Governance - MLOps  at scale\n",
    "- `3) DEV->TEST-PROD` (configs, compute, performance)\n",
    "    - ESML has config for 3 environemnts: Easy DEPLOY model across subscriptions and Azure ML Studio workspaces \n",
    "        - Save costs & time: \n",
    "            - `DEV` has cheaper compute performance for TRAIN and INFERENCE (batch, AKS)\n",
    "            - `DEV` has Quick-debug ML training (fast training...VS good scoring in TEST and PROD)\n",
    "        - How? ESML `AutoMLFactory` and `ComputeFactory`\n",
    "         \n",
    "\n",
    "### Q&A:\n",
    "- Q: Is ESML Machine learning specific? If I only want to refine some data...for integration, or report? \n",
    "- A: You can use this for just data refinement also: `Bronze->Silver->Gold` refinement.\n",
    "    - Benefits: Enterprise security, Read/write to datalake, easy to share refined data. \n",
    "    - Benefits: The tooling \"glued togehter\": Azure datafactory +  Azure Databricks (and Azure ML Studio pipelines if needed)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}